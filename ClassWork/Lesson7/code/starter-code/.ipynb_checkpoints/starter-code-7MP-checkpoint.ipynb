{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Practice/Demo\n",
    "\n",
    "The following code samples are provided directly from the lesson and should serve as a jumping off point for students to run the code on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.181366295108\n",
      "0.19044698065\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n",
    "\n",
    "df = pd.DataFrame({'x': range(100), 'y': range(100)})\n",
    "biased_df  = df.copy()\n",
    "biased_df.loc[:20, 'x'] = 1\n",
    "biased_df.loc[:20, 'y'] = 1\n",
    "\n",
    "def append_jitter(series):\n",
    "    jitter = np.random.random_sample(size=100)\n",
    "    return series + jitter\n",
    "\n",
    "df['x'] = append_jitter(df.x)\n",
    "df['y'] = append_jitter(df.y)\n",
    "\n",
    "biased_df['x'] = append_jitter(biased_df.x)\n",
    "biased_df['y'] = append_jitter(biased_df.y)\n",
    "\n",
    "## fit\n",
    "lm = linear_model.LinearRegression().fit(df[['x']], df['y'])\n",
    "print metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))\n",
    "\n",
    "## biased fit\n",
    "lm = linear_model.LinearRegression().fit(biased_df[['x']], biased_df['y'])\n",
    "print metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1673.46442266  This is the mean score of the generalized/K-Fold Model\n",
      "0.311645095081  This is the mean r2 of the K-Fold Model\n",
      "1672.58110765 This is the error for the model that takes everything\n",
      "0.311934605989  This is the r2 for the model that takes everything\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "wd = '../../assets/dataset/'\n",
    "bikeshare = pd.read_csv(wd + 'bikeshare.csv')\n",
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = bikeshare.casual\n",
    "\n",
    "kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True)\n",
    "scores = []\n",
    "rsquare = []\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    rsquare.append(metrics.r2_score(y.iloc[test_index],lm.predict(modeldata.iloc[test_index])))\n",
    "\n",
    "print np.mean(scores),\" This is the mean score of the generalized/K-Fold Model\"\n",
    "print np.mean(rsquare),\" This is the mean r2 of the K-Fold Model\"\n",
    "\n",
    "# this score will be lower, but we're trading off bias error for generalized error\n",
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata)),\"This is the error for the model that takes everything\"\n",
    "print metrics.r2_score(y, lm.predict(modeldata)),\" This is the r2 for the model that takes everything\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672.41958243\n",
      "The higher the number of folds, the more we genralize the set/worse fit\n",
      "0.316679057851  This is the mean r2 of the K-Fold Model with MORE Folds\n"
     ]
    }
   ],
   "source": [
    "#Now we're going to add more folds.\n",
    "MoreK = cross_validation.KFold(len(modeldata), n_folds=1000, shuffle=True)\n",
    "MoreKScores=[]\n",
    "Morersquare = []\n",
    "for train, test in MoreK:\n",
    "    newLM = linear_model.LinearRegression().fit(modeldata.iloc[train],y.iloc[train])\n",
    "    MoreKScores.append(metrics.mean_squared_error(y.iloc[test], lm.predict(modeldata.iloc[test])))\n",
    "    Morersquare.append(metrics.r2_score(y.iloc[test_index],lm.predict(modeldata.iloc[test_index])))\n",
    "print np.mean(MoreKScores)\n",
    "print \"The higher the number of folds, the more we genralize the set/worse fit\"\n",
    "print np.mean(Morersquare),\" This is the mean r2 of the K-Fold Model with MORE Folds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780.97924083\n"
     ]
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=False)\n",
    "scores = []\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    scores.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    \n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we look at the error for a different number of folds\n",
    "errorscore = []\n",
    "foldnum = []\n",
    "for fold in range(2,20):\n",
    "    errorfold = cross_validation.KFold(len(modeldata), n_folds=fold, shuffle=True)\n",
    "    foldnum.append(fold)\n",
    "    folds=[]\n",
    "    for train, test in errorfold:\n",
    "        foldtest = linear_model.LinearRegression().fit(modeldata.iloc[train],y.iloc[train])\n",
    "        folds.append(metrics.mean_squared_error(y.iloc[test], foldtest.predict(modeldata.iloc[test])))\n",
    "    errorscore.append(np.mean(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113986fd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113779dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "errors = pd.DataFrame(errorscore, index=foldnum, columns=[\"Error\"])\n",
    "errors.plot(kind=\"bar\", ylim=(1670,1750))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where we stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672.58110765\n",
      "1725.41581608\n",
      "1672.60490113\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "lm = linear_model.Lasso().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "lm = linear_model.Ridge().fit(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-10\n",
      "[ 112.68901765  -84.01121684  -24.68489063  -21.00314493  -21.71893628]\n",
      "1672.58110765\n",
      "Alpha: 1e-09\n",
      "[ 112.68901765  -84.01121684  -24.68489061  -21.00314491  -21.71893626]\n",
      "1672.58110765\n",
      "Alpha: 1e-08\n",
      "[ 112.68901765  -84.01121684  -24.6848904   -21.00314471  -21.71893606]\n",
      "1672.58110765\n",
      "Alpha: 1e-07\n",
      "[ 112.68901763  -84.01121682  -24.68488837  -21.00314268  -21.71893403]\n",
      "1672.58110765\n",
      "Alpha: 1e-06\n",
      "[ 112.68901745  -84.01121667  -24.68486804  -21.00312237  -21.71891373]\n",
      "1672.58110765\n",
      "Alpha: 1e-05\n",
      "[ 112.68901562  -84.01121509  -24.68466472  -21.00291929  -21.71871079]\n",
      "1672.58110765\n",
      "Alpha: 0.0001\n",
      "[ 112.68899732  -84.01119938  -24.68263174  -21.00088873  -21.71668161]\n",
      "1672.58110765\n",
      "Alpha: 0.001\n",
      "[ 112.68881437  -84.01104228  -24.66232204  -20.98060316  -21.69640993]\n",
      "1672.58110774\n",
      "Alpha: 0.01\n",
      "[ 112.68698753  -84.00947323  -24.46121539  -20.77973778  -21.49568404]\n",
      "1672.58111645\n",
      "Alpha: 0.1\n",
      "[ 112.66896732  -83.99396383  -22.63109556  -18.95202277  -19.66942371]\n",
      "1672.58185208\n",
      "Alpha: 1.0\n",
      "[ 112.50129738  -83.84805622  -13.38214934   -9.72671278  -10.46162477]\n",
      "1672.60490113\n",
      "Alpha: 10.0\n",
      "[ 110.96062533  -82.49604961   -3.94431741   -0.51765034   -1.45024412]\n",
      "1672.83347262\n",
      "Alpha: 100.0\n",
      "[ 97.69060562 -71.17602377  -0.31585194   1.18284675  -1.33281591]\n",
      "1686.31830362\n",
      "Alpha: 1000.0\n",
      "[ 44.59923075 -30.85843772   5.07876321   0.05369643  -5.107457  ]\n",
      "1937.81576044\n",
      "Alpha: 10000.0\n",
      "[ 7.03007064 -5.07733082  3.29039029 -1.2136063  -2.06842808]\n",
      "2314.83675678\n",
      "Alpha: 100000.0\n",
      "[ 0.75195708 -0.56490872  0.52067881 -0.25075496 -0.26895254]\n",
      "2415.77806566\n",
      "Alpha: 1000000.0\n",
      "[ 0.07576571 -0.05727511  0.05520142 -0.0273591  -0.02774349]\n",
      "2429.28026459\n",
      "Alpha: 10000000.0\n",
      "[ 0.00758239 -0.00573569  0.0055535  -0.00276043 -0.00278317]\n",
      "2430.68891798\n",
      "Alpha: 100000000.0\n",
      "[ 0.0007583  -0.00057365  0.00055569 -0.00027629 -0.00027841]\n",
      "2430.83041212\n",
      "Alpha: 1000000000.0\n",
      "[  7.58303020e-05  -5.73659720e-05   5.55719458e-05  -2.76314619e-05\n",
      "  -2.78414555e-05]\n",
      "2430.84456787\n",
      "Alpha: 10000000000.0\n",
      "[  7.58303603e-06  -5.73660542e-06   5.55722818e-06  -2.76317091e-06\n",
      "  -2.78415441e-06]\n",
      "2430.84598351\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(modeldata, y)\n",
    "    print lm.coef_\n",
    "    print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814.09369133\n",
      "Ridge(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, solver='auto', tol=0.001)\n",
      "[mean: -1817.58711, std: 542.14315, params: {'alpha': 1e-10}, mean: -1817.58711, std: 542.14315, params: {'alpha': 1.0000000000000001e-09}, mean: -1817.58711, std: 542.14315, params: {'alpha': 1e-08}, mean: -1817.58711, std: 542.14315, params: {'alpha': 9.9999999999999995e-08}, mean: -1817.58711, std: 542.14315, params: {'alpha': 9.9999999999999995e-07}, mean: -1817.58711, std: 542.14317, params: {'alpha': 1.0000000000000001e-05}, mean: -1817.58707, std: 542.14331, params: {'alpha': 0.0001}, mean: -1817.58663, std: 542.14477, params: {'alpha': 0.001}, mean: -1817.58230, std: 542.15933, params: {'alpha': 0.01}, mean: -1817.54318, std: 542.30102, params: {'alpha': 0.10000000000000001}, mean: -1817.20111, std: 543.63587, params: {'alpha': 1.0}, mean: -1814.09369, std: 556.35563, params: {'alpha': 10.0}, mean: -1818.51694, std: 653.68607, params: {'alpha': 100.0}, mean: -2125.58777, std: 872.45270, params: {'alpha': 1000.0}, mean: -2458.08836, std: 951.30428, params: {'alpha': 10000.0}, mean: -2532.21151, std: 962.80083, params: {'alpha': 100000.0}, mean: -2541.38479, std: 963.98339, params: {'alpha': 1000000.0}, mean: -2542.32833, std: 964.10141, params: {'alpha': 10000000.0}, mean: -2542.42296, std: 964.11321, params: {'alpha': 100000000.0}, mean: -2542.43242, std: 964.11439, params: {'alpha': 1000000000.0}, mean: -2542.43337, std: 964.11450, params: {'alpha': 10000000000.0}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Ridge(),\n",
    "    param_grid={'alpha': alphas},\n",
    "    scoring='mean_squared_error')\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print -gs.best_score_ # mean squared error here comes in negative, so let's make it positive.\n",
    "print gs.best_estimator_ # explains which grid_search setup worked best\n",
    "print gs.grid_scores_ # shows all the grid pairings and their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2 is better than 6.2\n",
      "found better solution! using 5.2\n",
      "4.2 is better than 5.2\n",
      "found better solution! using 4.2\n",
      "3.2 is better than 4.2\n",
      "found better solution! using 3.2\n",
      "2.2 is better than 3.2\n",
      "found better solution! using 2.2\n",
      "1.2 is better than 2.2\n",
      "found better solution! using 1.2\n",
      "0.2 is better than 1.2\n",
      "found better solution! using 0.2\n",
      "6.0 is closest to 6.2\n"
     ]
    }
   ],
   "source": [
    "num_to_approach, start, steps, optimized = 6.2, 0., [-1, 1], False\n",
    "while not optimized:\n",
    "    current_distance = num_to_approach - start\n",
    "    got_better = False\n",
    "    next_steps = [start + i for i in steps]\n",
    "    for n in next_steps:\n",
    "        distance = np.abs(num_to_approach - n)\n",
    "        if distance < current_distance:\n",
    "            got_better = True\n",
    "            print distance, 'is better than', current_distance\n",
    "            current_distance = distance\n",
    "            start = n\n",
    "    if got_better:\n",
    "        print 'found better solution! using', current_distance\n",
    "        a += 1\n",
    "    else:\n",
    "        optimized = True\n",
    "        print start, 'is closest to', num_to_approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29417393852\n",
      "1715.75455763\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.SGDRegressor()\n",
    "lm.fit(modeldata, y)\n",
    "print lm.score(modeldata, y)\n",
    "print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice\n",
    "\n",
    "Use the following code to work through the problems given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ESTIMATOR\n",
      "1728.17387156\n",
      "SGDRegressor(alpha=0.0001, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss',\n",
      "       n_iter=5, penalty='l2', power_t=0.25, random_state=None,\n",
      "       shuffle=False, verbose=0, warm_start=False)\n",
      "ALL ESTIMATORS\n",
      "[mean: -1728.17387, std: 31.31547, params: {}]\n"
     ]
    }
   ],
   "source": [
    "params = {} # put your gradient descent parameters here\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.SGDRegressor(),\n",
    "    cv=cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True),\n",
    "    param_grid=params,\n",
    "    scoring='mean_squared_error',\n",
    "    )\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'BEST ESTIMATOR'\n",
    "print -gs.best_score_\n",
    "print gs.best_estimator_\n",
    "print 'ALL ESTIMATORS'\n",
    "print gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
