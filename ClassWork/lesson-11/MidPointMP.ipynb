{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GA Data Science 31\n",
    "Instructor: Amy Roberts, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Course Part 1 review:   \n",
    "**Algorithms:** \n",
    "1. KNN \n",
    "2. Regression\n",
    "3. Logistic Regression\n",
    "\n",
    "\n",
    "**Key Concepts:**  \n",
    "\n",
    "1. bias and variance\n",
    "2. standard deviation\n",
    "3. standard error\n",
    "4. MSE/RMSE\n",
    "5. Confidence intervals\n",
    "6. R-square\n",
    "7. Under/overfitting\n",
    "8. Cross validation\n",
    "9. dummy coding \n",
    "\n",
    "**Classification model considerations **\n",
    "1. Imbalanced Classes\n",
    "2. ROC curves\n",
    "3. Percision vs Recall  \n",
    "--plus a note on Probablity, Odds, and Odds Ratios--  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General imports\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN \n",
    "Classifing unknown observations based on their neighbors\n",
    " \n",
    " |Continuous | Categorical \n",
    "--- | --- | --- \n",
    "supervised | regression | **classification**\n",
    "upsupervised | dimension reduction | clustering\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm | Type | Outcome |  Model |Key Steps | Model fit | Interpretation\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "kNN| Supervised |Categorical (classifier) | Non-parmetric, lazy| Train/Test, selecting K | Accruacy cross-validation | This obeservation belongs to group X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scikit \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(train[features], train[outcome])\n",
    "\n",
    "#determine how many ks\n",
    "results = []\n",
    "for n in range(1, 51, 2):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    clf.fit(train[features], train[outcome])\n",
    "    preds = clf.predict(test[features])\n",
    "    score = clf.score(test[features], test[outcome])\n",
    "    \n",
    "    print \"Neighbors: %d, Score: %3f\" % (n, score)\n",
    "    \n",
    "    results.append([n, score])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Regression\n",
    "Fit a line to our data where coefficients are estimated using the least squares criterion.  This means we find the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\") \n",
    "\n",
    "Algorithm | Type | Outcome |  Model |Key Steps | Model fit | Interpretation\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "Linear Regression| Supervised | Continuous | Parmetric| Determining covariates  |R square and Adj R square | **categorical covar:** Compared to [reference category], we would expect [category of interest] to be [b-coeffienct] more/less of outcome (e.g., compared to shrubs that were in partial sun, we would expect shrubs in full sun to be 11 cm taller, on average, at the same level of soil bacteria. Where 11 is the beta coeeffient for shurb height) **continuous covar:** For every [beta-coeffient] of covariate there will be a 1 unit change in the outcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the standard import if you're using \"formula notation\" (similar to R)\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# create a fitted model in one line\n",
    "#formula notiation is the equivalent to writting out our models such that 'outcome = predictor'\n",
    "#with the follwing syntax formula = 'outcome ~ predictor1 + predictor2 ... predictorN'\n",
    "lm = smf.ols(formula='outcome ~ covariate', data=data).fit()\n",
    "\n",
    "#print the full summary\n",
    "lm.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression\n",
    "Fit a line to our data where coefficients are estimated using the least squares criterion.  This means we find the line (mathematically) which minimizes the sum of squared residuals (or \"sum of squared errors\") \n",
    "\n",
    "Algorithm | Type | Outcome |  Model |Key Steps | Model fit | Interpretation\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "Logistic Regression| Supervised | Categorical | Parmetric| Determining covariates, convert coeffients to odds ratios or predicted probablities  |R square and Adj R square or ML | **categorical covar:** exposed \"times the odds\" of getting outcome compared to unexposed. **continuous covar:** every unit increase in covar multiplies the odds of survival by OR (e.g., every year increase in age multiplies the odds of survival by 0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logit = sm.Logit(data[outcome], data[train_cols])\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms covered so far\n",
    "\n",
    "Algorithm | Type | Outcome |  Model |Key Steps | Model fit | Interpretation\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "kNN| Supervised |Categorical (classifier) | Non-parmetric, lazy| Train/Test, selecting K | Accruacy cross-validation | This obeservation belongs to group X\n",
    "Linear Regression| Supervised | Continuous | Parmetric| Determining covariates  |R square and Adj R square | **categorical covar:** Compared to [reference category], we would expect [category of interest] to be [b-coeffienct] more/less of outcome (e.g., compared to shrubs that were in partial sun, we would expect shrubs in full sun to be 11 cm taller, on average, at the same level of soil bacteria. Where 11 is the beta coeeffient for shurb height) **continuous covar:** For every [beta-coeffient] of covariate there will be a 1 unit change in the outcome\n",
    "Logistic Regression| Supervised | Categorical | Parmetric| Determining covariates, convert coeffients to odds ratios or predicted probablities  |R square and Adj R square or ML | **categorical covar:** exposed \"times the odds\" of getting outcome compared to unexposed. **continuous covar:** every unit increase in covar multiplies the odds of survival by OR (e.g., every year increase in age multiplies the odds of survival by 0.94)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error due to Bias:** The error due to bias is taken as the difference between the expected (or average) prediction of our model and the correct value which we are trying to predict. Imagine you could repeat the whole model building process more than once: each time you gather new data and run a new analysis creating a new model. Due to randomness in the underlying data sets, the resulting models will have a range of predictions. Bias measures how far off in general these models' predictions are from the correct value.  \n",
    "**Error due to Variance:** The error due to variance is taken as the variability of a model prediction for a given data point. Again, imagine you can repeat the entire model building process multiple times. The variance is how much the predictions for a given point vary between different realizations of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img(src='images/biasVsVarianceImage.png', style=\"width: 30%; height: 30%\")>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. Standard Deviation \n",
    "In statistics, the standard deviation (SD, also represented by the Greek letter sigma, Ïƒ for the population standard deviation or s for the sample standard deviation) is a measure that is used to quantify the amount of variation or  dispersion of a set of data values. **It is the square root of the variance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Standard Error\n",
    "The standard error of the mean (SEM) quantifies the precision of the mean. It is a measure of how far your sample mean is likely to be from the true population mean. It is expressed in the same units as the data.\n",
    "\n",
    "As the standard error of an estimated value generally increases with the size of the estimate, a large standard error may not necessarily result in an unreliable estimate. Therefore it is often better to compare the error in relation to the size of the estimate.\n",
    "\n",
    "Recall that the regression line is the line that minimizes the sum of squared deviations of prediction (also called the sum of squares error). The standard error of the estimate is closely related to this quantity and is defined below:\n",
    "\n",
    "         Ïƒest = sqrt((sum(Y-Y')^2)/N )\n",
    "\n",
    "where Ïƒest is the standard error of the estimate, Y is an actual score, Y' is a predicted score, and N is the number of pairs of scores. The numerator is the sum of squared differences between the actual scores and the predicted scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4. MSE/RMSE\n",
    "MSE- mean/average of the square of all of the error. It is a measure of both variance and bias. \n",
    "RMSE- The square root of the MSE\n",
    "\n",
    "The use of RMSE is very common and it makes an excellent general purpose error metric for numerical predictions.\n",
    "Compared to the similar Mean Absolute Error, RMSE amplifies and severely punishes large errors.\n",
    "\n",
    "For an unbiased estimator, the RMSE is the square root of the variance, known as the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5. Confidence Intervals/P-values\n",
    "**Confidence Intervals** The 95% confidence interval is measured by two standard errors either side of the estimate. If the population from which this sample was drawn was sampled 100 times, approximately 95 of those confidence intervals would contain the \"true\" coefficient.\n",
    "\n",
    "**Hypothesis testing** Generally speaking, you start with a null hypothesis and an alternative hypothesis (that is opposite the null). Then, you check whether the data supports rejecting the null hypothesis or failing to reject the null hypothesis.\n",
    "(Note that \"failing to reject\" the null is not the same as \"accepting\" the null hypothesis. The alternative hypothesis may indeed be true, except that you just don't have enough data to show that.)\n",
    "\n",
    "As it relates to model coefficients, here is the conventional hypothesis test:  \n",
    "null hypothesis: There is no relationship between TV ads and Sales (and thus Î²1 equals zero)  \n",
    "alternative hypothesis: There is a relationship between TV ads and Sales (and thus Î²1 is not equal to zero)  \n",
    "\n",
    "**How do we test this hypothesis?** Intuitively, we reject the null (and thus believe the alternative) if the 95% confidence interval does not include zero (or 1 for ratio measures). Conversely, the p-value represents the probability that the coefficient is actually zero. Generally we look for a p-value less 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6. R squared\n",
    "The most common way to evaluate the overall fit of a linear model is by the R-squared value. **R-squared is the proportion of variance explained**, meaning the proportion of variance in the observed data that is explained **by the model**, or the reduction in error over the null model. (The null model just predicts the mean of the observed response, and thus it has an intercept and no slope.)\n",
    "\n",
    "R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model. \n",
    "\n",
    "**limitations of R-squared **\n",
    "\n",
    "1. Linear/logistic models rely upon a lot of assumptions (such as the features being independent), and if those assumptions are violated (which they usually are), R-squared and p-values are less reliable.\n",
    "\n",
    "2. R-squared is susceptible to overfitting, and thus there is no guarantee that a model with a high R-squared value will generalize.\n",
    "\n",
    "3. R-squared will always increase as you add more features to the model, even if they are unrelated to the response.\n",
    "\n",
    "Thus, selecting the model with the highest R-squared is not a reliable approach for choosing the best linear model.\n",
    "There is alternative to R-squared called **adjusted R-squared that penalizes model complexity (to control for overfitting), but it generally under-penalizes complexity.**\n",
    "\n",
    "**For feature selection: consider using:**\n",
    "So is there a better approach to feature selection? Cross-validation. It provides a more reliable estimate of out-of-sample error, and thus is a better way to choose which of your models will best generalize to out-of-sample data. There is extensive functionality for cross-validation in scikit-learn, including automated methods for searching different sets of parameters and different models. Importantly, cross-validation can be applied to any model, whereas the methods described above only apply to linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7. Under and Overfitting\n",
    "Typically our goal is to use our model to predict some outside --new-- data using a model that we create with data we currently have for our analysis. Under and over fitting refer to creating a model that \n",
    "1. Under fitting: Does not sufficiently capture the variance of our predictors\n",
    "2. Over Fitting: Captures the variance of our current data well, but does not capture the outside --new-- data. aka it's too specific to our current data.\n",
    "\n",
    "**We use Train and Test techniques to protect against overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img(src='images/trainTest.png', style=\"width: 50%; height: 50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8. Cross Validation\n",
    "Often times only doing a training and test set 1 time is not sufficient to insure that your model is fitting well. Cross validation is a standardized why to repeat the train/testing sets to increase our confidence in our prediction model.\n",
    "How many folds are needed? [source](http://research.cs.tamu.edu/prism/lectures/iss/iss_l13.pdf)\n",
    "\n",
    "**With a large number of folds:**  \n",
    "1. The **bias of the true error rate estimator** will be **small** (the estimator will be very accurate)\n",
    "2. The **variance of the true error rate estimator** will be **large**\n",
    "3. The **computational time will be very large** as well (many experiments) If you reduce number of folds (aka: the number of experiments) the computation time is reduced\n",
    "4. The **variance of the estimator** will be **small**\n",
    "5. The **bias of the estimator** will be **large** (conservative or higher than the true error rate) \n",
    "\n",
    "In practice, the choice of the number of folds depends on the size of the dataset n.   \n",
    "**For large datasets, even 3-Fold Cross Validation will be quite accurate**  \n",
    "**For very sparse datasets,** we may have to use leave-one-out in order to train on as many examples as possible g  **A common choice for K-Fold Cross Validation is K=10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img(src='images/crossValidationImage.png', style=\"width: 50%; height: 50%\")>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(classifer_or_model, data_to_fit, optional_variable_to_predicted, cv=10)\n",
    "#note cv is the number of folds (K) and is optional. If not specified 3 will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9. Class/Dummy Variables\n",
    "We have to represent categorical variables numerically, but we can't simply code it as 0=rural, 1=suburban, 2=urban because that would imply an **ordered relationship** between suburban and urban (and thus urban is somehow \"twice\" the suburban category).\n",
    "\n",
    "Why do we only need **two dummy variables, not three?** Because two dummies capture all of the information about the Area feature, and implicitly defines rural as the reference level. (In general, if you have a categorical feature with k levels, you create k-1 dummy variables.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create three dummy variables using get_dummies, then exclude the first dummy column\n",
    "my_categorical_var_dummies = pd.get_dummies(my_categorical_var, prefix='Area').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special considerations and tools for Classifers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1. Imbalanced Classes\n",
    "If there are a lot more a certain category than the comparison category, the imbalance will confuse many classifiers as they will only perform well on the dominant class and poorly on the minority class. This can be a major problem if you are manianly intersted in the uncommon class (e.g., cancer, fraud).\n",
    "\n",
    "Solutions: \n",
    "1. Undersampling the dominant class - remove some the majority class so it has less weight  \n",
    "    *Drawback: Removing datapoints could lose important information*\n",
    "2. Oversampling the minority class - add more of the minority class so it has more weight.  \n",
    "    *Drawback: Just replicating randomly minority classes could cause overfit*\n",
    "3. Hybrid - doing both is better--> [SMOTE](https://www.jair.org/media/953/live-953-2037-jair.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2. ROC- a more sophisticated way to capture misclassification\n",
    "\n",
    "There are 4 key consdierations when it comes to measuring the goodness of a classification model: \n",
    "\n",
    "<img(src='images/typesOfMisclassificationImage.png', style=\"width: 50%; height: 50%\")>\n",
    "\n",
    "Sensitivity: True Postitive Rate\n",
    "Specificity: False Positive Rate\n",
    "\n",
    "<img(src='images/ROCurveImage.png', style=\"width: 25%; height: 25%\")>\n",
    "We evaluate a classifier by measuring the area under the curve for its ROC curve. The Greater area under the curve, the more effective the classifier.\n",
    "\n",
    "Then for our chosen classifer, we pick an appropriate decision threshold. In general, we pick the decision threshold that gets us closest to the upper left corner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba, this_label):\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label= this_label + ', ROC Area = %0.3f' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('ROC')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3. Precision vs Recall\n",
    "\n",
    "**Precision** is the percentage of True Positives in your set of results  \n",
    "**Recall** is True Postives / Total Positives. (aka: Same as True Positive Rate/ sensitivity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Pseudocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "\n",
    "#related 2X2 \n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note Probability, Odds and  Odds ratios\n",
    "In logistic regression, Î²1 represents the change in the log-odds for a\n",
    "unit change in x.\n",
    "\n",
    "This means that e^(Î²1) gives us the change in the odds for a unit change in x.\n",
    "\n",
    "Odds Ratios can be calcuated as the (odds in the exposed group)/(odds in the unexposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability: the number of ways that an event can occur divided by the total number of possible outcomes. \n",
    "\n",
    "The probability of drawing a red card from a standard deck of cards is 26/52 (50 percent). \n",
    "The probability of drawing a club from that deck is 13/52 (25 percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the probability of getting heads in a fair coin flip? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The odds for an event is the ratio of the number of ways the event can occur to the number of ways it does not occur.\n",
    "\n",
    "For example, using the same events as above, the odds for:\n",
    "drawing a red card from a standard deck of cards is 1:1; and\n",
    "drawing a club from that deck is 1:3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####What's the odds of a fair coin flip?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppose that 18 out of 20 patients in an experiment lost weight while using diet A, while 16 out of 20  lost weight using diet B.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####What's the probability of weight loss with diet A? What's the odds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "#90 percent probability,\n",
    "probabilityA = 18/20.0\n",
    "print probabilityA\n",
    "\n",
    "oddsA = 18/2.0\n",
    "print oddsA\n",
    "#often stated \"the odds of weight loss are 9:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####What's the probablity of weight loss with diet B? What's the odds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#(80 percent, odds of 4:1)\n",
    "probabilityB = 16/20.0\n",
    "print probabilityB\n",
    "oddsB = 16/4.0\n",
    "print oddsB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####What's the odds ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25\n"
     ]
    }
   ],
   "source": [
    "OR_A = oddsA/oddsB\n",
    "print OR_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: Participants study diet A had 2.25 times the odds of weightloss compared to those in study group B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.444444444444\n"
     ]
    }
   ],
   "source": [
    "OR_B = oddsB/oddsA\n",
    "print OR_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: Participants on study diet B had 0.44 times the odds of weightloss compared to those in study group A. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####What if this was a continous variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we do a logistic regression on maternal age and to predict probability of giving birth to a child with birth defects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Write out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P(no defect) = alpha + Beta1(maternal age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####We run the regression and find an OR of 0.94 with a 95% confidence interval of (0.90, 0.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: For every 1 year increase in age, mothers have 0.94 times the odds of having a healthy baby. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-----------------------------------------------------\n",
    "\n",
    "-----------------------------------------------------**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#So what's next? \n",
    "Week | Tuesday | Thursday\n",
    "--- | --- | ---\n",
    "6 | 2/23: Flex |  **UNIT 3** 2/25:  Decision trees and random forest\n",
    " 7 | 3/1: Natural Language Processing | 3/3: Dimensionality reduction\n",
    " 8 | 3/8: Time series data | 3/10:  Create models with time series data\n",
    " 9 | 3/15: Database technologies | 3/17: Final project work session\n",
    "10 | 3/22: Whatâ€™s next? | 3/24: Final project presentations\n",
    "11 | 3/29: Final project presentations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reading for Thursday\n",
    "\n",
    "Resources\n",
    "scikit-learn documentation: [Decision Trees](http://scikit-learn.org/stable/modules/tree.html)  \n",
    "Wikipedia: http://en.wikipedia.org/wiki/Decision_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
