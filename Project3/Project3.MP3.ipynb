{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit  gre   gpa  prestige\n",
      "0      0  380  3.61         3\n",
      "1      1  660  3.67         3\n",
      "2      1  800  4.00         1\n",
      "3      1  640  3.19         4\n",
      "4      0  520  2.93         4\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency\n",
       "2        148\n",
       "3        121\n",
       "4         67\n",
       "1         61"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "count = pd.Series(df[\"prestige\"])\n",
    "count = pd.DataFrame(count.value_counts())\n",
    "count.columns = [\"Frequency\"]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xabcf940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEVCAYAAADwyx6sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntOBJ5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab6ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count.plot(kind=\"Bar\")\n",
    "plt.xlabel(\"Prestige\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prest_dummies = pd.get_dummies(df[\"prestige\"],prefix=\"prestige\",prefix_sep=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We only need three, we're going to use 4 as our reference variable. So we can drop the 4th dummy variable since if 1,2 and 3 = '0' then we know it ='s 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Odds Ratio Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odds of getting in to a school with prestige_1.0 are 0.540984\n",
      "The odds of getting in to a school with prestige_2.0 are 0.358108\n",
      "The odds of getting in to a school with prestige_3.0 are 0.231405\n",
      "The odds of getting in to a school with prestige_4.0 are 0.179104\n",
      "\n",
      "The odds ratio for each prestige level is: \n",
      "Prestige 1: 0.354839\n",
      "Prestige 2: 0.726027\n",
      "Prestige 3: 0.285714\n",
      "Prestige 4: 0.105263\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = df[cols_to_keep].join(prest_dummies.ix[:, :\"prestige_3.0\"])\n",
    "outC = len(handCalc)\n",
    "#Could not think of a more efficient way to predict odds\n",
    "odd1 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_1.0\"]==1)])\n",
    "no1 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_1.0\"]==0)])\n",
    "odd2 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_2.0\"]==1)])\n",
    "no2 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_2.0\"]==0)])\n",
    "odd3 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_3.0\"]==1)])\n",
    "no3 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_3.0\"]==0)])\n",
    "odd4 = len(handCalc[(handCalc[\"admit\"]==1) & (handCalc[\"prestige_3.0\"]==0) & (handCalc[\"prestige_2.0\"]==0) &\\\n",
    "                    (handCalc[\"prestige_1.0\"]==0)])\n",
    "no4 = len(handCalc[(handCalc[\"admit\"]==1) & ((handCalc[\"prestige_3.0\"]==1) | (handCalc[\"prestige_2.0\"]==1) |\\\n",
    "                    (handCalc[\"prestige_1.0\"]==1))])\n",
    "\n",
    "#Tried using iteritems for making these lists but had troble. I know there is a more efficient way\n",
    "prest1 = len(handCalc[handCalc[\"prestige_1.0\"]==1])\n",
    "prest2 = len(handCalc[handCalc[\"prestige_2.0\"]==1])\n",
    "prest3 = len(handCalc[handCalc[\"prestige_3.0\"]==1])\n",
    "prest4 = len(handCalc[(handCalc[\"prestige_3.0\"]==0) & (handCalc[\"prestige_2.0\"]==0) &\\\n",
    "                    (handCalc[\"prestige_1.0\"]==0)])\n",
    "#Creating Lists\n",
    "oddlist = [odd1, odd2, odd3, odd4]\n",
    "nolist = [no1, no2, no3, no4]\n",
    "prest_list = [prest1,prest2,prest3,prest4]\n",
    "head_list = list(handCalc.columns[3:6])\n",
    "head_list.append(\"prestige_4.0\")\n",
    "#Odds for getting in based on each prestige\n",
    "for i in range(len(oddlist)):\n",
    "    print \"The odds of getting in to a school with %s are %f\" % (head_list[i], oddlist[i]/prest_list[i])\n",
    "\n",
    "                                                                               \n",
    "print \"\\nThe odds ratio for each prestige level is: \"\n",
    "# Calculating odds ratio, i.e. the odds of getting in with prestige N vs. odds getting with without prestige \"N\"\n",
    "print \"Prestige 1: %f\" % (odd1/no1)\n",
    "print \"Prestige 2: %f\" % (odd2/no2)\n",
    "print \"Prestige 3: %f\" % (odd3/no3)\n",
    "print \"Prestige 4: %f\" % (odd4/no4)\n",
    "#It appears I calculated the odds ratio against not getting in, is this not what was asked for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige_1.0    0   1\n",
       "admit                \n",
       "0             243  28\n",
       "1              93  33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crosstab prestige 1 admission \n",
    "pd.crosstab(handCalc[\"admit\"], handCalc[\"prestige_1.0\"], rownames=[\"admit\"], colnames=[\"prestige_1.0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odds of being admitted to grad school if you attended a #1 ranked college are 33/28\n",
      "1.18\n"
     ]
    }
   ],
   "source": [
    "print \"odds of being admitted to grad school if you attended a #1 ranked college are 33/28\"\n",
    "prest1 = round(33/28,2)\n",
    "print prest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382716049383\n"
     ]
    }
   ],
   "source": [
    "prest1null = 93/243\n",
    "print prest1null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odds ratio is: 3.083226\n"
     ]
    }
   ],
   "source": [
    "print \"The odds ratio is: %f\" % (prest1/prest1null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We have identified a relationship that one is more likely to have gained entry into graduate school if they went to a school with a prestige of 1 by a magnitude of 3 compared to if they had gone elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1       0           1\n",
       "2       0       1   0\n",
       "3       0   1   0   0\n",
       "admit                \n",
       "0      55  93  95  28\n",
       "1      12  28  53  33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(handCalc[\"admit\"],[handCalc[\"prestige_1.0\"],handCalc[\"prestige_2.0\"],handCalc[\"prestige_3.0\"]],\\\n",
    "            rownames=[\"admit\"], colnames=[\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 x\n"
     ]
    }
   ],
   "source": [
    "odd4=12/(55)\n",
    "no4=55/(12)\n",
    "OR4 = odd4/no4\n",
    "print \"%s x\" % (round(OR4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds ratio indicates that you are much less likely to gain acceptance to graduate school if you went to a prestige 4 school. For example, the odds that you do not get in are substantially higher than the odds that you do get in since the odds ratio is less than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0\n",
       "0      0  380  3.61             0             0             1\n",
       "1      1  660  3.67             0             0             1\n",
       "2      1  800  4.00             1             0             0\n",
       "3      1  640  3.19             0             0             0\n",
       "4      0  520  2.93             0             0             0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "#After finding prestige 3.0 was not significant, took away 3.0\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(prest_dummies.ix[:, :\"prestige_3.0\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  intercept\n",
       "0      0  380  3.61             0             0             1          1\n",
       "1      1  660  3.67             0             0             1          1\n",
       "2      1  800  4.00             1             0             0          1\n",
       "3      1  640  3.19             0             0             0          1\n",
       "4      0  520  2.93             0             0             0          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statsmodels.discrete.discrete_model.Logit"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cols = sm.Logit(data[\"admit\"],data.ix[:,1:7])\n",
    "type(train_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "logit_mod = train_cols.fit(disp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 29 Feb 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>09:46:34</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128     1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_1.0</th> <td>    1.5534</td> <td>    0.417</td> <td>    3.721</td> <td> 0.000</td> <td>    0.735     2.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>    0.8733</td> <td>    0.367</td> <td>    2.378</td> <td> 0.017</td> <td>    0.153     1.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>    0.2147</td> <td>    0.393</td> <td>    0.547</td> <td> 0.584</td> <td>   -0.555     0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -5.4303</td> <td>    1.140</td> <td>   -4.764</td> <td> 0.000</td> <td>   -7.664    -3.196</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 29 Feb 2016   Pseudo R-squ.:                 0.08166\n",
       "Time:                        09:46:34   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.176e-07\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gre              0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
       "gpa              0.7793      0.333      2.344      0.019         0.128     1.431\n",
       "prestige_1.0     1.5534      0.417      3.721      0.000         0.735     2.372\n",
       "prestige_2.0     0.8733      0.367      2.378      0.017         0.153     1.593\n",
       "prestige_3.0     0.2147      0.393      0.547      0.584        -0.555     0.984\n",
       "intercept       -5.4303      1.140     -4.764      0.000        -7.664    -3.196\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod.summary()\n",
    "#Prestige 3.0 is not significant, so ran again without adding 3.0\n",
    "#I know that this degrades the possibility of saying anything about 4.0 prestiges,\n",
    "#but none of the questions below are worried about it and since its our reference variable \n",
    "#both Prestige 1.0 and 2.0 are referencing gaining acceptance vs. prestige 4. If I need to I can run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "<em>In this case, the coefficient is the log of the odds ratio for variable and its counterpart. So running the anti log or `np.exp`for each coefficient should provide the log ratio for each. <font color=\"red\">This also assumes we're using the 'e' as our base it looks like.</font></em>\n",
    "\n",
    "hint 2: conf['OR'] = params <em>Using params did not work for me, I needed to call confidence interval</em>\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "\n",
    "\n",
    "I found this helpful <a href=http://www.ats.ucla.edu/stat/mult_pkg/faq/general/odds_ratio.htm>How to interpret odds ratio</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_Ratio</th>\n",
       "      <th>2.5%</th>\n",
       "      <th>97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.002218</td>\n",
       "      <td>1.002221</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.779337</td>\n",
       "      <td>2.180027</td>\n",
       "      <td>0.127619</td>\n",
       "      <td>1.431056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <td>1.553411</td>\n",
       "      <td>4.727566</td>\n",
       "      <td>0.735197</td>\n",
       "      <td>2.371624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <td>0.873274</td>\n",
       "      <td>2.394738</td>\n",
       "      <td>0.153432</td>\n",
       "      <td>1.593115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <td>0.214733</td>\n",
       "      <td>1.239531</td>\n",
       "      <td>-0.554669</td>\n",
       "      <td>0.984135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Coefficient  Odds_Ratio      2.5%     97.5%\n",
       "gre              0.002218    1.002221  0.000074  0.004362\n",
       "gpa              0.779337    2.180027  0.127619  1.431056\n",
       "prestige_1.0     1.553411    4.727566  0.735197  2.371624\n",
       "prestige_2.0     0.873274    2.394738  0.153432  1.593115\n",
       "prestige_3.0     0.214733    1.239531 -0.554669  0.984135"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_coef = pd.DataFrame(logit_mod.params, columns=[\"Coefficient\"])\n",
    "model_coef[\"OR\"] = model_coef.apply(np.exp, axis = 1)\n",
    "model_coef.head()\n",
    "model_ci = pd.DataFrame(logit_mod.conf_int())\n",
    "model_coef = model_coef.join(model_ci)\n",
    "model_coef.columns = [\"Coefficient\", \"Odds_Ratio\", \"2.5%\",\"97.5%\"]\n",
    "model_coef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Holding other variables constant, we can say that the odds for getting into a school while attending a prestige 2.0 institution are 2.4x higher than if attending a prestige 4 school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Holding other variables constant, we can say that the odds for getting into a school increase 2.18x for each increase in unit of the natural log of the GPA. <font color=\"red\">This is because of an interesting properties with natural logs, and I believe logs in general where a unit increase in a natural log is the same as that percentage increase to the outcome.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0953101798043\n",
      "0.0953101798043\n",
      "0.0953101798043\n",
      "0.0953101798043\n",
      "0.0953101798043\n",
      "The difference between the natural log of one number and 10% more of that same number\n"
     ]
    }
   ],
   "source": [
    "#basic list of numbers\n",
    "unit_list = [1,5,10,25,100]\n",
    "unit_ln = np.log(unit_list)\n",
    "#Basic list of numbers increased 10%\n",
    "unit_list10 = []\n",
    "for i in unit_list:\n",
    "    unit_list10.append(i*1.1)\n",
    "unit10_ln = np.log(unit_list10)\n",
    "#Difference between the natural log of original numbers and numbers increased by 10%\n",
    "for i in range(len(unit_list)):\n",
    "    print unit10_ln[i]-unit_ln[i]\n",
    "print \"The difference between the natural log of one number and 10% more of that same number\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 220.          284.44444444  348.88888889  413.33333333  477.77777778\n",
      "  542.22222222  606.66666667  671.11111111  735.55555556  800.        ]\n",
      "[ 2.26        2.45333333  2.64666667  2.84        3.03333333  3.22666667\n",
      "  3.42        3.61333333  3.80666667  4.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mpress\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:42: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\mpress\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:44: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]), columns=[\"GRE\",\"GPA\",\"prestige\",\"intercept\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE       GPA  prestige  intercept\n",
       "0  220  2.260000         1          1\n",
       "1  220  2.260000         2          1\n",
       "2  220  2.260000         3          1\n",
       "3  220  2.260000         4          1\n",
       "4  220  2.453333         1          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0             1             0             0             0\n",
       "1             0             1             0             0\n",
       "2             0             0             1             0\n",
       "3             0             0             0             1\n",
       "4             1             0             0             0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dummies = pd.get_dummies(combos[\"prestige\"],prefix=\"prestige\")\n",
    "new_dummies.head()\n",
    "#Keeping prestige 3.0 in this case. But still dropping prestige 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige</th>\n",
       "      <th>intercept</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE       GPA  prestige  intercept  prestige_1.0  prestige_2.0  \\\n",
       "0  220  2.260000         1          1             1             0   \n",
       "1  220  2.260000         2          1             0             1   \n",
       "2  220  2.260000         3          1             0             0   \n",
       "3  220  2.260000         4          1             0             0   \n",
       "4  220  2.453333         1          1             1             0   \n",
       "\n",
       "   prestige_3.0  prestige_4.0  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             1             0  \n",
       "3             0             1  \n",
       "4             0             0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Joining dummy variables\n",
    "combos = combos.join(new_dummies)\n",
    "combos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dropping the duplicate \"prestige\" column and the reference variable column\n",
    "combos = combos.drop(\"prestige_4.0\", axis=1)\n",
    "combos = combos.drop(\"prestige\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>intercept</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>185.334387</td>\n",
       "      <td>0.556003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.433555</td>\n",
       "      <td>0.433555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>348.888889</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>671.111111</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GRE         GPA  intercept  prestige_1.0  prestige_2.0  \\\n",
       "count  400.000000  400.000000        400    400.000000    400.000000   \n",
       "mean   510.000000    3.130000          1      0.250000      0.250000   \n",
       "std    185.334387    0.556003          0      0.433555      0.433555   \n",
       "min    220.000000    2.260000          1      0.000000      0.000000   \n",
       "25%    348.888889    2.646667          1      0.000000      0.000000   \n",
       "50%    510.000000    3.130000          1      0.000000      0.000000   \n",
       "75%    671.111111    3.613333          1      0.250000      0.250000   \n",
       "max    800.000000    4.000000          1      1.000000      1.000000   \n",
       "\n",
       "       prestige_3.0  \n",
       "count    400.000000  \n",
       "mean       0.250000  \n",
       "std        0.433555  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.250000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE       GPA  prestige_1.0  prestige_2.0  prestige_3.0  intercept\n",
       "0  220  2.260000             1             0             0          1\n",
       "1  220  2.260000             0             1             0          1\n",
       "2  220  2.260000             0             0             1          1\n",
       "3  220  2.260000             0             0             0          1\n",
       "4  220  2.453333             1             0             0          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reordering columns because its easier\n",
    "cols = ['GRE', 'GPA',  'prestige_1.0', 'prestige_2.0', 'prestige_3.0','intercept']\n",
    "#cols = ['GRE', 'GPA',  'prestige_1.0', 'prestige_2.0', 'prestige_3.0']\n",
    "combos = combos[cols]\n",
    "combos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction Statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction Statsmodels\n",
       "0                0.164173\n",
       "1                0.090492\n",
       "2                0.048977\n",
       "3                0.039890\n",
       "4                0.185907"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the outcome based on all the values using the combos DF\n",
    "predictions_statsmodels = pd.DataFrame(logit_mod.predict(combos),columns=[\"Prediction Statsmodels\"])\n",
    "predictions_statsmodels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction Statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.260753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.153057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.138621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.227298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.353954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.734040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction Statsmodels\n",
       "count              400.000000\n",
       "mean                 0.260753\n",
       "std                  0.153057\n",
       "min                  0.039890\n",
       "25%                  0.138621\n",
       "50%                  0.227298\n",
       "75%                  0.353954\n",
       "max                  0.734040"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_statsmodels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combos = combos.join(predictions_statsmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "      <th>Prediction Statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE       GPA  prestige_1.0  prestige_2.0  prestige_3.0  intercept  \\\n",
       "0  220  2.260000             1             0             0          1   \n",
       "1  220  2.260000             0             1             0          1   \n",
       "2  220  2.260000             0             0             1          1   \n",
       "3  220  2.260000             0             0             0          1   \n",
       "4  220  2.453333             1             0             0          1   \n",
       "\n",
       "   Prediction Statsmodels  \n",
       "0                0.164173  \n",
       "1                0.090492  \n",
       "2                0.048977  \n",
       "3                0.039890  \n",
       "4                0.185907  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "      <th>Prediction Statsmodels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE  GPA  prestige_1.0  prestige_2.0  prestige_3.0  intercept  \\\n",
       "396  800    4             1             0             0          1   \n",
       "397  800    4             0             1             0          1   \n",
       "398  800    4             0             0             1          1   \n",
       "399  800    4             0             0             0          1   \n",
       "\n",
       "     Prediction Statsmodels  \n",
       "396                0.734040  \n",
       "397                0.582995  \n",
       "398                0.419833  \n",
       "399                0.368608  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: With a GRE of 400 and a GPA of 4 you are getting into grad school since we with a 37% probability, but holding other variables constant. However, we have a much better chance of getting in, over 70% if we had the same GRE scores and GPA but went to a more prestigious institution.\n",
    "However, it would be better to use \"predict_proba\" so we can find the range, so we need to use SciKitLearn because I like that better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  intercept\n",
       "0      0  380  3.61             0             0             1          1\n",
       "1      1  660  3.67             0             0             1          1\n",
       "2      1  800  4.00             1             0             0          1\n",
       "3      1  640  3.19             0             0             0          1\n",
       "4      0  520  2.93             0             0             0          1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the model is:  0.700251889169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logprob = LogisticRegression()\n",
    "#Ignoring intercept since SKLearn can handle it\n",
    "log_model = logprob.fit(data.ix[:,1:6],data[\"admit\"])\n",
    "#Ignoring compos intercept\n",
    "print \"The score of the model is: \",log_model.score(data.ix[:,1:6], data[\"admit\"])\n",
    "prediction_sci = pd.DataFrame(log_model.predict_proba(combos.ix[:,0:5]),columns=[\"no admit\",\"Prediction SciKit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "results = combos.join(prediction_sci[\"Prediction SciKit\"])\n",
    "results.head()\n",
    "print type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Not sure exactly what I want to do here. I don't want to use a pivot table, I want to see if I can use a groupby\n",
    "with the DataFrame and then apply a function accross a GPA group. I stack overflowed it and I don't like the results and they \n",
    "look wrong</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Prediction SciKit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.260000</th>\n",
       "      <td>0.225170</td>\n",
       "      <td>0.218690</td>\n",
       "      <td>0.327907</td>\n",
       "      <td>0.477543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.453333</th>\n",
       "      <td>0.225176</td>\n",
       "      <td>0.218696</td>\n",
       "      <td>0.327914</td>\n",
       "      <td>0.477552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.646667</th>\n",
       "      <td>0.225182</td>\n",
       "      <td>0.218702</td>\n",
       "      <td>0.327922</td>\n",
       "      <td>0.477560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.840000</th>\n",
       "      <td>0.225188</td>\n",
       "      <td>0.218708</td>\n",
       "      <td>0.327930</td>\n",
       "      <td>0.477569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.033333</th>\n",
       "      <td>0.225194</td>\n",
       "      <td>0.218714</td>\n",
       "      <td>0.327937</td>\n",
       "      <td>0.477578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.226667</th>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.218720</td>\n",
       "      <td>0.327945</td>\n",
       "      <td>0.477587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.420000</th>\n",
       "      <td>0.225206</td>\n",
       "      <td>0.218726</td>\n",
       "      <td>0.327953</td>\n",
       "      <td>0.477595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.613333</th>\n",
       "      <td>0.225212</td>\n",
       "      <td>0.218732</td>\n",
       "      <td>0.327961</td>\n",
       "      <td>0.477604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.806667</th>\n",
       "      <td>0.225219</td>\n",
       "      <td>0.218738</td>\n",
       "      <td>0.327968</td>\n",
       "      <td>0.477613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.000000</th>\n",
       "      <td>0.225225</td>\n",
       "      <td>0.218744</td>\n",
       "      <td>0.327976</td>\n",
       "      <td>0.477621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Prediction SciKit                              \n",
       "prestige_1.0                 0                             1\n",
       "prestige_2.0                 0                   1         0\n",
       "prestige_3.0                 0         1         0         0\n",
       "GPA                                                         \n",
       "2.260000              0.225170  0.218690  0.327907  0.477543\n",
       "2.453333              0.225176  0.218696  0.327914  0.477552\n",
       "2.646667              0.225182  0.218702  0.327922  0.477560\n",
       "2.840000              0.225188  0.218708  0.327930  0.477569\n",
       "3.033333              0.225194  0.218714  0.327937  0.477578\n",
       "3.226667              0.225200  0.218720  0.327945  0.477587\n",
       "3.420000              0.225206  0.218726  0.327953  0.477595\n",
       "3.613333              0.225212  0.218732  0.327961  0.477604\n",
       "3.806667              0.225219  0.218738  0.327968  0.477613\n",
       "4.000000              0.225225  0.218744  0.327976  0.477621"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPAG = results.pivot_table(values=[\"Prediction SciKit\"], index=[\"GPA\"], columns=['prestige_1.0','prestige_2.0','prestige_3.0'],\\\n",
    "                           aggfunc = np.mean)\n",
    "GPAG.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb7e3748>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEPCAYAAACqZsSmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP2agtZmKXdzqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb7e3ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPAG.plot()\n",
    "plt.legend(['4','3','2','1'],title='school prestige')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Prediction SciKit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th colspan=\"3\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220.000000</th>\n",
       "      <td>0.151864</td>\n",
       "      <td>0.147024</td>\n",
       "      <td>0.232704</td>\n",
       "      <td>0.365298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284.444444</th>\n",
       "      <td>0.165528</td>\n",
       "      <td>0.160335</td>\n",
       "      <td>0.251485</td>\n",
       "      <td>0.389350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348.888889</th>\n",
       "      <td>0.180160</td>\n",
       "      <td>0.174604</td>\n",
       "      <td>0.271245</td>\n",
       "      <td>0.413952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413.333333</th>\n",
       "      <td>0.195782</td>\n",
       "      <td>0.189855</td>\n",
       "      <td>0.291953</td>\n",
       "      <td>0.438992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477.777778</th>\n",
       "      <td>0.212408</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>0.313561</td>\n",
       "      <td>0.464346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542.222222</th>\n",
       "      <td>0.230041</td>\n",
       "      <td>0.223366</td>\n",
       "      <td>0.336009</td>\n",
       "      <td>0.489885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606.666667</th>\n",
       "      <td>0.248677</td>\n",
       "      <td>0.241630</td>\n",
       "      <td>0.359224</td>\n",
       "      <td>0.515478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671.111111</th>\n",
       "      <td>0.268296</td>\n",
       "      <td>0.260886</td>\n",
       "      <td>0.383117</td>\n",
       "      <td>0.540989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735.555556</th>\n",
       "      <td>0.288867</td>\n",
       "      <td>0.281108</td>\n",
       "      <td>0.407589</td>\n",
       "      <td>0.566288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800.000000</th>\n",
       "      <td>0.310347</td>\n",
       "      <td>0.302256</td>\n",
       "      <td>0.432527</td>\n",
       "      <td>0.591245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Prediction SciKit                              \n",
       "prestige_1.0                 0                             1\n",
       "prestige_2.0                 0                   1         0\n",
       "prestige_3.0                 0         1         0         0\n",
       "GRE                                                         \n",
       "220.000000            0.151864  0.147024  0.232704  0.365298\n",
       "284.444444            0.165528  0.160335  0.251485  0.389350\n",
       "348.888889            0.180160  0.174604  0.271245  0.413952\n",
       "413.333333            0.195782  0.189855  0.291953  0.438992\n",
       "477.777778            0.212408  0.206107  0.313561  0.464346\n",
       "542.222222            0.230041  0.223366  0.336009  0.489885\n",
       "606.666667            0.248677  0.241630  0.359224  0.515478\n",
       "671.111111            0.268296  0.260886  0.383117  0.540989\n",
       "735.555556            0.288867  0.281108  0.407589  0.566288\n",
       "800.000000            0.310347  0.302256  0.432527  0.591245"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GREG = results.pivot_table(values=[\"Prediction SciKit\"], index=[\"GRE\"], columns=['prestige_1.0','prestige_2.0','prestige_3.0'], \\\n",
    "                           aggfunc = np.mean)\n",
    "GREG.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xc1decf8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEPCAYAAABMTw/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLO7/A2idhcui2qM1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbf2bc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GREG.plot()\n",
    "plt.legend(['4','3','2','1'],title='school prestige')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>GPA</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>intercept</th>\n",
       "      <th>Prediction Statsmodels</th>\n",
       "      <th>Prediction SciKit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.365261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>0.232675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048977</td>\n",
       "      <td>0.147004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.039890</td>\n",
       "      <td>0.151844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>0.365269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103682</td>\n",
       "      <td>0.232682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056492</td>\n",
       "      <td>0.147008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>220</td>\n",
       "      <td>2.453333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046078</td>\n",
       "      <td>0.151848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>220</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209795</td>\n",
       "      <td>0.365277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118543</td>\n",
       "      <td>0.232688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>220</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065080</td>\n",
       "      <td>0.147013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>220</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053173</td>\n",
       "      <td>0.151853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>220</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.235865</td>\n",
       "      <td>0.365286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>220</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135214</td>\n",
       "      <td>0.232694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>220</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074871</td>\n",
       "      <td>0.147017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>220</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.061290</td>\n",
       "      <td>0.151857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>220</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264090</td>\n",
       "      <td>0.365294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>220</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153820</td>\n",
       "      <td>0.232701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>220</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085999</td>\n",
       "      <td>0.147022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>220</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.151862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>220</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294393</td>\n",
       "      <td>0.365302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174469</td>\n",
       "      <td>0.232707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>220</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098605</td>\n",
       "      <td>0.147026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>220</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081096</td>\n",
       "      <td>0.151867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>220</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326629</td>\n",
       "      <td>0.365311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>220</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197244</td>\n",
       "      <td>0.232714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>220</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112831</td>\n",
       "      <td>0.147031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>220</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093056</td>\n",
       "      <td>0.151871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>220</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360591</td>\n",
       "      <td>0.365319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>220</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222192</td>\n",
       "      <td>0.232720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>800</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201304</td>\n",
       "      <td>0.302237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>800</td>\n",
       "      <td>2.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.168977</td>\n",
       "      <td>0.310328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>800</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527768</td>\n",
       "      <td>0.591232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>800</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361479</td>\n",
       "      <td>0.432514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>800</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226621</td>\n",
       "      <td>0.302245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>800</td>\n",
       "      <td>2.840000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191201</td>\n",
       "      <td>0.310336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>800</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565093</td>\n",
       "      <td>0.591241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>800</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396929</td>\n",
       "      <td>0.432523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>800</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254108</td>\n",
       "      <td>0.302252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>800</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215590</td>\n",
       "      <td>0.310344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>800</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.601694</td>\n",
       "      <td>0.591250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>800</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433495</td>\n",
       "      <td>0.432532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>800</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283707</td>\n",
       "      <td>0.302260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>800</td>\n",
       "      <td>3.226667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.310351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>800</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.637193</td>\n",
       "      <td>0.591258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>800</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0.432540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>800</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315296</td>\n",
       "      <td>0.302267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>800</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270871</td>\n",
       "      <td>0.310359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>800</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.671257</td>\n",
       "      <td>0.591267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>800</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508433</td>\n",
       "      <td>0.432549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>800</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.348690</td>\n",
       "      <td>0.302275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>800</td>\n",
       "      <td>3.613333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301632</td>\n",
       "      <td>0.310366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>800</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703609</td>\n",
       "      <td>0.591276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>800</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545972</td>\n",
       "      <td>0.432558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>800</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.383639</td>\n",
       "      <td>0.302282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>800</td>\n",
       "      <td>3.806667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334286</td>\n",
       "      <td>0.310374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734040</td>\n",
       "      <td>0.591284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582995</td>\n",
       "      <td>0.432567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419833</td>\n",
       "      <td>0.302290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368608</td>\n",
       "      <td>0.310382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE       GPA  prestige_1.0  prestige_2.0  prestige_3.0  intercept  \\\n",
       "0    220  2.260000             1             0             0          1   \n",
       "1    220  2.260000             0             1             0          1   \n",
       "2    220  2.260000             0             0             1          1   \n",
       "3    220  2.260000             0             0             0          1   \n",
       "4    220  2.453333             1             0             0          1   \n",
       "5    220  2.453333             0             1             0          1   \n",
       "6    220  2.453333             0             0             1          1   \n",
       "7    220  2.453333             0             0             0          1   \n",
       "8    220  2.646667             1             0             0          1   \n",
       "9    220  2.646667             0             1             0          1   \n",
       "10   220  2.646667             0             0             1          1   \n",
       "11   220  2.646667             0             0             0          1   \n",
       "12   220  2.840000             1             0             0          1   \n",
       "13   220  2.840000             0             1             0          1   \n",
       "14   220  2.840000             0             0             1          1   \n",
       "15   220  2.840000             0             0             0          1   \n",
       "16   220  3.033333             1             0             0          1   \n",
       "17   220  3.033333             0             1             0          1   \n",
       "18   220  3.033333             0             0             1          1   \n",
       "19   220  3.033333             0             0             0          1   \n",
       "20   220  3.226667             1             0             0          1   \n",
       "21   220  3.226667             0             1             0          1   \n",
       "22   220  3.226667             0             0             1          1   \n",
       "23   220  3.226667             0             0             0          1   \n",
       "24   220  3.420000             1             0             0          1   \n",
       "25   220  3.420000             0             1             0          1   \n",
       "26   220  3.420000             0             0             1          1   \n",
       "27   220  3.420000             0             0             0          1   \n",
       "28   220  3.613333             1             0             0          1   \n",
       "29   220  3.613333             0             1             0          1   \n",
       "..   ...       ...           ...           ...           ...        ...   \n",
       "370  800  2.646667             0             0             1          1   \n",
       "371  800  2.646667             0             0             0          1   \n",
       "372  800  2.840000             1             0             0          1   \n",
       "373  800  2.840000             0             1             0          1   \n",
       "374  800  2.840000             0             0             1          1   \n",
       "375  800  2.840000             0             0             0          1   \n",
       "376  800  3.033333             1             0             0          1   \n",
       "377  800  3.033333             0             1             0          1   \n",
       "378  800  3.033333             0             0             1          1   \n",
       "379  800  3.033333             0             0             0          1   \n",
       "380  800  3.226667             1             0             0          1   \n",
       "381  800  3.226667             0             1             0          1   \n",
       "382  800  3.226667             0             0             1          1   \n",
       "383  800  3.226667             0             0             0          1   \n",
       "384  800  3.420000             1             0             0          1   \n",
       "385  800  3.420000             0             1             0          1   \n",
       "386  800  3.420000             0             0             1          1   \n",
       "387  800  3.420000             0             0             0          1   \n",
       "388  800  3.613333             1             0             0          1   \n",
       "389  800  3.613333             0             1             0          1   \n",
       "390  800  3.613333             0             0             1          1   \n",
       "391  800  3.613333             0             0             0          1   \n",
       "392  800  3.806667             1             0             0          1   \n",
       "393  800  3.806667             0             1             0          1   \n",
       "394  800  3.806667             0             0             1          1   \n",
       "395  800  3.806667             0             0             0          1   \n",
       "396  800  4.000000             1             0             0          1   \n",
       "397  800  4.000000             0             1             0          1   \n",
       "398  800  4.000000             0             0             1          1   \n",
       "399  800  4.000000             0             0             0          1   \n",
       "\n",
       "     Prediction Statsmodels  Prediction SciKit  \n",
       "0                  0.164173           0.365261  \n",
       "1                  0.090492           0.232675  \n",
       "2                  0.048977           0.147004  \n",
       "3                  0.039890           0.151844  \n",
       "4                  0.185907           0.365269  \n",
       "5                  0.103682           0.232682  \n",
       "6                  0.056492           0.147008  \n",
       "7                  0.046078           0.151848  \n",
       "8                  0.209795           0.365277  \n",
       "9                  0.118543           0.232688  \n",
       "10                 0.065080           0.147013  \n",
       "11                 0.053173           0.151853  \n",
       "12                 0.235865           0.365286  \n",
       "13                 0.135214           0.232694  \n",
       "14                 0.074871           0.147017  \n",
       "15                 0.061290           0.151857  \n",
       "16                 0.264090           0.365294  \n",
       "17                 0.153820           0.232701  \n",
       "18                 0.085999           0.147022  \n",
       "19                 0.070553           0.151862  \n",
       "20                 0.294393           0.365302  \n",
       "21                 0.174469           0.232707  \n",
       "22                 0.098605           0.147026  \n",
       "23                 0.081096           0.151867  \n",
       "24                 0.326629           0.365311  \n",
       "25                 0.197244           0.232714  \n",
       "26                 0.112831           0.147031  \n",
       "27                 0.093056           0.151871  \n",
       "28                 0.360591           0.365319  \n",
       "29                 0.222192           0.232720  \n",
       "..                      ...                ...  \n",
       "370                0.201304           0.302237  \n",
       "371                0.168977           0.310328  \n",
       "372                0.527768           0.591232  \n",
       "373                0.361479           0.432514  \n",
       "374                0.226621           0.302245  \n",
       "375                0.191201           0.310336  \n",
       "376                0.565093           0.591241  \n",
       "377                0.396929           0.432523  \n",
       "378                0.254108           0.302252  \n",
       "379                0.215590           0.310344  \n",
       "380                0.601694           0.591250  \n",
       "381                0.433495           0.432532  \n",
       "382                0.283707           0.302260  \n",
       "383                0.242159           0.310351  \n",
       "384                0.637193           0.591258  \n",
       "385                0.470800           0.432540  \n",
       "386                0.315296           0.302267  \n",
       "387                0.270871           0.310359  \n",
       "388                0.671257           0.591267  \n",
       "389                0.508433           0.432549  \n",
       "390                0.348690           0.302275  \n",
       "391                0.301632           0.310366  \n",
       "392                0.703609           0.591276  \n",
       "393                0.545972           0.432558  \n",
       "394                0.383639           0.302282  \n",
       "395                0.334286           0.310374  \n",
       "396                0.734040           0.591284  \n",
       "397                0.582995           0.432567  \n",
       "398                0.419833           0.302290  \n",
       "399                0.368608           0.310382  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPAdeux = results\n",
    "GPAdeux = GPAdeux.groupby([\"GPA\",\"GRE\"])\n",
    "GPAdeux.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
